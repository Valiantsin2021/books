# Notes

## Sources

[Introduction to Data](https://app.datacamp.com/learn/courses/introduction-to-data)

[Introduction to Data Culture](https://app.datacamp.com/learn/courses/introduction-to-data-culture)

[Introduction to Data Quality](https://app.datacamp.com/learn/courses/introduction-to-data-quality)

## [Introduction to Data](https://app.datacamp.com/learn/courses/introduction-to-data)

### Structured vs Unstructured data

Customer info, Financial transactions vs Email, Video

![Image description](https://dev-to-uploads.s3.amazonaws.com/uploads/articles/2t881wvg8r6ouzmhuccf.png)

### Quantitative vs Qualitative data

![Image description](https://dev-to-uploads.s3.amazonaws.com/uploads/articles/9e4zlksqc0eo77v2ohhx.png)

### Data Context

![Image description](https://dev-to-uploads.s3.amazonaws.com/uploads/articles/v1qwhj8tyujpp72on2dn.png)

![Image description](https://dev-to-uploads.s3.amazonaws.com/uploads/articles/rppvutaumamzfdfvqod0.png)

### DIKW pyramid (4 layer model):

1. Data
2. Information
3. Knowledge
4. Wisdom

Start with raw data, organize it into information interpret it into knowledge & wisdom.

![Image description](https://dev-to-uploads.s3.amazonaws.com/uploads/articles/307uvnuxqk92rl3yoc9k.png)

Wisdom: Because it will probably rain tonight and make the park muddy, James' parents should plan some alternative games for their fifteen quests.

### Data decision making

![Image description](https://dev-to-uploads.s3.amazonaws.com/uploads/articles/n1n1fti5knlcsi9d0dxz.png)

Asking the right question will:

- ﻿﻿Outline exact what you are looking to answer
- ﻿﻿Prevent scope creep
- ﻿﻿Ensure success throughout the rest of the process

Gather the right data for your question:

- ﻿﻿Data can live in multiple locations
- ﻿﻿Think ahead to your analysis, you can save time and effort now

Prepare data for analysis:

- ﻿﻿Clean bad to good data
- ﻿﻿Arrange data into expected structure for analysis
- ﻿﻿Sometimes most time consuming task

Analyzing data; decisions are based on data analysis. Here are some tools:

- ﻿﻿Python, R
- ﻿﻿Tableau, Power BI
- ﻿﻿Excel, Google Sheets

Making decisions:

- ﻿﻿The last step of the data-driven process
- ﻿﻿Better decisions based on data, especially when combined with personal experiences
- ﻿﻿Iterative process

![Image description](https://dev-to-uploads.s3.amazonaws.com/uploads/articles/ycnzb27oe9cqlbmt5ca3.png)

- 

### Principles of data ethics

1. ﻿﻿﻿Permission for data collection
2. ﻿﻿﻿Transparency about the plan
3. ﻿﻿﻿Privacy of data
4. ﻿﻿﻿Good intentions
5. ﻿﻿﻿Consider the outcome

### What is the data life cycle?

- ﻿﻿Planning and collecting
- ﻿﻿Storing and managing
- ﻿﻿Cleaning and processing
- ﻿﻿Analyzing and visualizing
- ﻿﻿Sharing
- ﻿﻿Archiving/destroying

![Image description](https://dev-to-uploads.s3.amazonaws.com/uploads/articles/off9fgvju6c4zty14m30.png)

## [Introduction to Data Culture](https://app.datacamp.com/learn/courses/introduction-to-data-culture)

### Key components of data culture

- Making data-driven decisions
  - ﻿﻿Evaluate strategy
  - ﻿﻿Identify opportunities
  - ﻿﻿Measure success
  - ﻿﻿Evidence over intuition or opinion
- Prioritize data literacy: being able to read, interpret and analyze data
- Continuous experimentation and development

Benefits:

- ﻿﻿Enhanced decision-making

- ﻿﻿Improved operations

- Efficiency boost

  

### Data challenges

#### People related

Data silos:

- Occur when information is isolated within teams or departments
- ﻿﻿Hamper collaboration, limit organizational understanding
- ﻿﻿Example:
  * Ford's siloed data storage
- ﻿﻿Solutions:
  * Centralized data team/data management system

Data literacy:

- ﻿﻿Reluctance to gain new skills and adapt to changing data trend
- ﻿﻿Failure to invest in long-term commitment
- ﻿﻿Example:
  - ﻿﻿Assume all employees have the same level of data literacy
- ﻿﻿Solutions:
  - ﻿﻿Customized training program
  - ﻿﻿Continuously monitoring and refining

﻿﻿Data ethics:

- ﻿﻿Responsible, fair, and transparent data usage
- ﻿﻿Example:
   o Amazon's biased hiring algorithm
- ﻿﻿Solutions:
  - ﻿﻿Establish clear ethical guidelines
  - ﻿﻿Foster open discussion

#### Process related

Data quality:

- ﻿﻿Data needs to be ﻿accurate, reliable, up-to-date

* Example:
  - ﻿﻿Uber's "Greyball" resulted in severe consequences

* ﻿﻿Solutions:

  * Implement data validation process

  - ﻿﻿Leverage automated data cleansing tools

Data privacy & security:

- Extended data usage may lead to overlook of data privacy and data security
- ﻿﻿Protecting sensitive information maintains customer trust and avoid potential breaches
- ﻿﻿Example: 2017 Equifax data breach
- ﻿﻿Solutions:
  - ﻿﻿Implement access controls
  - ﻿﻿Apply encryption techniques
  - ﻿﻿Conduct regular security checks

### 5 level data maturity model

1. Awareness: the organization knows that data is important but lacks a plan for how to understand and analyze its data.
2. Adoption: some stakeholders within the organization have attempted to make data-informed decisions but the approach is often limited or siloed.
3. Standardization: achieved by breaking through the siloes between different pockets of the organization and acting as one unified vision.
4. Optimization: this is when the organizations try to improve efficiency by coordinating between different groups and data stream.
5. Innovation: a data culture is born and data's value, importance, and utility is realized at every level.

![Image description](https://dev-to-uploads.s3.amazonaws.com/uploads/articles/6usj9omw2w8svqusypt6.png)

![Image description](https://dev-to-uploads.s3.amazonaws.com/uploads/articles/b8xrn213txy7hr5nsdme.png)

## [Introduction to Data Quality](https://app.datacamp.com/learn/courses/introduction-to-data-quality)

**Critical for Decision-Making**: High-quality data is essential for informed business decisions, directly affecting trust and value in the data used.

**Key Activities for Quality**: Maintaining good data quality requires monitoring, timely issue resolution, and awareness of data's value among those who handle it.

**Benefits**: Good data quality provides competitive advantages and risk mitigation, enhancing customer service and preventing operational issues.

![Image description](https://dev-to-uploads.s3.amazonaws.com/uploads/articles/v75kmlq6v9jrpv5cdqjd.png)

### Data quality dimensions

Data completeness example:
![Image description](https://dev-to-uploads.s3.amazonaws.com/uploads/articles/vgpe5guycgeihtfoohfc.png)

Data validity example:
![Image description](https://dev-to-uploads.s3.amazonaws.com/uploads/articles/g988lhlbo0igw5fjzrhd.png)

Data uniqueness example:![Image description](https://dev-to-uploads.s3.amazonaws.com/uploads/articles/8d16pkmzgrtn9fr381zh.png)

Data consistency example:![Image description](https://dev-to-uploads.s3.amazonaws.com/uploads/articles/dgsc4maosr3ylaq11667.png)

Data accuracy example:![Image description](https://dev-to-uploads.s3.amazonaws.com/uploads/articles/xln47okyi4hnjtsh1ju7.png)

![Image description](https://dev-to-uploads.s3.amazonaws.com/uploads/articles/an6hrr4ieckn4phsrw0u.png)

### Data quality rules examples

![Image description](https://dev-to-uploads.s3.amazonaws.com/uploads/articles/cqmao5w1sjysvtugva3t.png)

### Data quality roles

**Data Producers**: Individuals or systems responsible for creating, collecting, and managing data. Their duties include implementing and adhering to data quality rules, setting alerts for data issues, and fixing any identified problems.

**Data Consumers**: Users or systems that utilize data for analysis, reporting, or operational purposes. They are tasked with evaluating the quality of data before use, providing feedback on data quality rules based on business needs, and reporting any data quality issues to producers.

**Data Governance Team**: A group responsible for the oversight of the data quality program, including the establishment and enforcement of data quality policies and standards, monitoring data quality metrics, and ensuring the provision of necessary tools and training for maintaining data quality.

![Image description](https://dev-to-uploads.s3.amazonaws.com/uploads/articles/hjvukce5rytrsrewwn4g.png)

### Data profiling

Data profiling: The activity of running statistics on a data set to better understand the data and field dependencies

Examples:

- ﻿﻿How many records are in the data set?
- ﻿﻿What are the min and max values for a particular data element?
- ﻿﻿How many records have a particular data element populated?
- ﻿﻿When column A is populated, what other columns are also populated?

![Image description](https://dev-to-uploads.s3.amazonaws.com/uploads/articles/c9gwnvabw67b966ntra6.png)

### Metadata

Attributes that describe data.

- ﻿﻿Used to organize and understand datasets and data elements
- ﻿﻿Used in the data quality process to determine the:
   o definition of a field
   o owner of a field
   o field's last update date

![Image description](https://dev-to-uploads.s3.amazonaws.com/uploads/articles/4p8p34gdvi1hpjub33k0.png)

**Data lineage**: A representation of how data moves in a pipeline, from where the data is entered in the source through each step in the data pipeline, until it is consumed.

- ﻿﻿Each layer has its own metadata
- ﻿﻿Used in the data quality process to determine where to implement a data quality rule

![Image description](https://dev-to-uploads.s3.amazonaws.com/uploads/articles/08pdj26uwc50vbgdea6b.png)

### Using Data lineage and Metadata

![Image description](https://dev-to-uploads.s3.amazonaws.com/uploads/articles/nh66q5ot5pyheaxzorey.png)

![Image description](https://dev-to-uploads.s3.amazonaws.com/uploads/articles/adgbvtckbjvkrp7nggqq.png)

![Image description](https://dev-to-uploads.s3.amazonaws.com/uploads/articles/nyy8o7ecilstty13yuf2.png)

![Image description](https://dev-to-uploads.s3.amazonaws.com/uploads/articles/f4k7ksneitdbyb6je0e0.png)

![Image description](https://dev-to-uploads.s3.amazonaws.com/uploads/articles/j1itut6e9st4ze9c04qr.png)

### Data quality rules in action

**Detective data quality rule**: rule that monitors the data after it has already been loaded into the downstream target databases where it can be consumed. Ok if we can fix later and we can live with a low percentage of issues; we do not block data to be loaded.

![Image description](https://dev-to-uploads.s3.amazonaws.com/uploads/articles/iq5ou6nmy3vbs17a0d2a.png)

![Image description](https://dev-to-uploads.s3.amazonaws.com/uploads/articles/kqhjpcliq1uvmbcas84s.png)

**Preventative data quality rule:** stops the data from loading. Use it when the data is critical, or can be easily fixed, or impacts a high amount of records.

![Image description](https://dev-to-uploads.s3.amazonaws.com/uploads/articles/1p9yd18ki7x3e8a43j1y.png)

![Image description](https://dev-to-uploads.s3.amazonaws.com/uploads/articles/l87outpvwv6dg9w00vyd.png)

### Anomaly detection

**Automated Data Monitoring**: Anomaly detection leverages machine learning algorithms to automatically identify potential data quality issues without needing constant human oversight, allowing for efficient monitoring of large datasets.

**Scalability and Insight**: It offers the ability to monitor data at scale, requiring minimal initial business knowledge to set up. Over time, it can detect data drift and provide insights into non-obvious changes in data patterns that may not be immediately apparent to the business.

**Complement to Traditional Rules**: While anomaly detection can automate and enhance data quality monitoring, especially in large datasets, it's most effective when used alongside traditional data quality rules, particularly in highly regulated industries that require rigorous data governance.

![Image description](https://dev-to-uploads.s3.amazonaws.com/uploads/articles/dxe6wz8hbkoudfdhzclr.png)

![Image description](https://dev-to-uploads.s3.amazonaws.com/uploads/articles/vzbiw1aievaq82egr73s.png)

Anomaly threshold alert example:
![Image description](https://dev-to-uploads.s3.amazonaws.com/uploads/articles/j2qb9j42jwd3ilmdnfbv.png)

![Image description](https://dev-to-uploads.s3.amazonaws.com/uploads/articles/mpausekkz73fq189ho17.png)
